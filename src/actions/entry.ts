"use server";

import { getUser } from "@/auth/server";
import prisma from "@/db/prisma";
import HfInference from "@/huggingface";
import { handleError } from "@/lib/utils";
import { Prisma } from "@prisma/client";
import { NextResponse } from "next/server";

export const createEntryAction = async (
  entryId: string,
  journalText: string,
) => {
  try {
    const user = await getUser();
    if (!user) throw new Error("You must be logged in to add a note");

    const oneWeekAgo = new Date();
    oneWeekAgo.setDate(oneWeekAgo.getDate() - 7);

    // const userPreference = await prisma.user.findUnique({
    //   where: {
    //     id: user.id,
    //   },
    //   select: {
    //     preference: true,
    //   },
    // });
    const userPreference = "Challenging";

    const entry = await prisma.entry.findMany({
      where: {
        authorId: user.id,
        createdAt: {
          gte: oneWeekAgo,
        },
      },
      orderBy: {
        createdAt: "desc",
      },
      select: {
        userResponse: true,
        createdAt: true,
        updatedAt: true,
        summary: true,
      },
    });
    let formattedEntry = "";
    if (entry.length > 0) {
      let formattedEntry = entry
        .map((entry) =>
          `
        Text: ${JSON.stringify(entry.userResponse)}
        Created at: ${entry.createdAt}
        Last updated: ${entry.updatedAt}
        Previous AI Summary: ${entry.summary}
      `.trim(),
        )
        .join("\n");
    }

    const messages = [
      {
        role: "system",
        content: `
          You are a helpful assistant that asks 4-6 insightful and reflective questions that are ${userPreference}, regarding a user's journal entry. You can use 7 days worth of context to ask insightful questions about their day to help them plan.
          
          Assume all questions were generated by you and all responses are from past entries from the week.
          
          Keep your responses short concise but conversational.

          Consider Input Types to make responses to questions more intresting:
          Input Type 1: Open Ended Paragraph
          Input Type 2: Close Ended Sentence
          Input Type 3: Likert Rating scale

          Return all questions in the format of valid JSON. All JSON objects should have a question and relevant input type, in the format below:
            
            [
              {
                "question": "Enter insightful question here",
                "inputType": 1-3
              },
              {
                "question": "Enter insightful question here",
                "inputType": 1-3
              },
            ]

          If there are no entries, start by learning about the person.
          
          Here are today's entries:
          ${journalText}

          Here are the Journal Entries from the week:
          ${formattedEntry}
        `,
      },
    ];
    const out = await HfInference.chatCompletion({
      model: "Qwen/Qwen3-32B",
      provider: "cerebras",
      messages,
      max_tokens: 1024,
      temperature: 0.1,
    });
    // console.log(out.choices[0].message.content);
    // return out.choices[0].message.content || "A problem has occured...";
    const rawSummary =
      out.choices?.[0]?.message?.content || "Error summarizing entry.";

    // Remove any <think>...</think> block (including multi-line content)
    const cleanSummary = rawSummary
      .replace(/<think>[\s\S]*?<\/think>/gi, "")
      .trim();

    console.log(cleanSummary);
    let parsedSummary = JSON.parse(cleanSummary);
    try {
      const createdEntry = await prisma.entry.create({
        data: {
          id: entryId,
          authorId: user.id,
          userResponse: cleanSummary,
          summary: '{"title": "Incomplete Entry"}',
          isOpen: "open",
          journalEntry: [
            {
              timestamp: new Date().toISOString(),
              text: journalText,
            },
          ],
        },
      });

      return { success: true, data: createdEntry };
    } catch (err) {
      if (err instanceof Prisma.PrismaClientKnownRequestError) {
        console.error("üõë Known Prisma Error:");
        console.error("Code:", err.code);
        console.error("Message:", err.message);
        console.error("Meta:", err.meta);
      } else if (err instanceof Prisma.PrismaClientValidationError) {
        console.error("üõ†Ô∏è Validation Error:", err.message);
      } else {
        console.error("‚ùì Unknown Error:", err);
      }

      return {
        success: false,
        message: "Failed to create entry. Check server logs for more details.",
      };
    }

    return { errorMessage: null };
  } catch (error) {
    return {
      success: false,
      message: error instanceof Error ? error.message : "Unknown error",
    };
  }
};

export const updateEntryAction = async (
  entryId: string,
  userResponse: Record<string, string>,
  summary: string,
) => {
  try {
    const user = await getUser();
    if (!user) throw new Error("You must be logged in to update a note");

    await prisma.entry.update({
      where: { id: entryId },
      data: { userResponse, summary, isOpen: "partial" },
    });

    return { errorMessage: null };
  } catch (error) {
    return handleError(error);
  }
};

export const deleteEntryAction = async (entryId: string) => {
  try {
    const user = await getUser();
    if (!user) throw new Error("You must be logged in to delete a note");

    await prisma.entry.delete({
      where: { id: entryId, authorId: user.id },
    });

    return { errorMessage: null };
  } catch (error) {
    return handleError(error);
  }
};

export const AskAIAboutEntryAction = async (
  newQuestion: string[],
  responses: string[],
) => {
  try {
    const user = await getUser();
    if (!user) throw new Error("You must be logged in to get AI responses");

    const entry = await prisma.entry.findMany({
      where: { authorId: user.id },
      orderBy: { createdAt: "desc" },
      select: {
        userResponse: true,
        createdAt: true,
        updatedAt: true,
        summary: true,
      },
    });

    if (entry.length === 0) {
      return "You don't have any journal entries yet";
    }

    const formattedEntry = entry
      .map((entry) =>
        `
        Text: ${JSON.stringify(entry.userResponse)}
        Created at: ${entry.createdAt}
        Last updated: ${entry.updatedAt}
        Previous AI Summary: ${entry.summary}
      `.trim(),
      )
      .join("\n");

    const messages = [
      {
        role: "system",
        content: `
          You are a helpful assistant that answers questions about a user's notes. 
          Assume all questions are related to the user's notes. 
          Keep answers succinct and return clean HTML. Use proper HTML tags: 
          <p>, <strong>, <em>, <ul>, <ol>, <li>, <h1>-<h6>, <br>, etc.
          
          Rendered like this in JSX:
          <p dangerouslySetInnerHTML={{ __html: YOUR_RESPONSE }} />
    
          Here are the user's notes:
          ${formattedEntry}
        `,
      },
    ];

    for (let i = 0; i < newQuestion.length; i++) {
      messages.push({ role: "user", content: newQuestion[i] });
      if (responses[i]) {
        messages.push({ role: "assistant", content: responses[i] });
      }
    }
    console.log(messages);
    const out = await HfInference.chatCompletion({
      model: "Qwen/Qwen3-32B",
      provider: "cerebras",
      messages,
      max_tokens: 512,
      temperature: 0.1,
    });
    console.log(out.choices[0].message.content);
    return out.choices[0].message.content || "A problem has occured...";

    return { errorMessage: null };
  } catch (error) {
    return handleError(error);
  }
};

type EntryObject = {
  [key: string]: string | undefined;
};

export const AISummaryAction = async (entry: EntryObject) => {
  try {
    const messages = [];

    const keys = Object.keys(entry);
    for (let i = 0; i < keys.length; i++) {
      const question = keys[i];
      const answer = entry[question];
      if (answer) {
        messages.push({ role: "user", content: question });
        messages.push({ role: "assistant", content: answer });
      }
    }

    const out = await HfInference.chatCompletion({
      model: "Qwen/Qwen3-32B",
      provider: "cerebras",
      messages: [
        {
          role: "system",
          content: `
            You are a helpful assistant that summarizes a user's journal entry. 
            Assume all responses to questions are related to the user's experiences. 
            Keep answers succinct and return a paragraph summary in second person, present tense looking to the future.

            Return all information in the format of valid JSON. All summaries should have a title a summarization, and 3 relevant tags. It should in the format below:
            
            {
              "title": "Enter a Passage Title Here",
              "summary": "Enter your Summary Here",
              "tags": ["Tag1", "Tag2", "Tag3"],
              "sentiment": 0.0
            }

            If the responses don't make sense return something about trying to set yourself up for success instead of just entering random answers.
          `,
        },
        ...messages,
      ],
      max_tokens: 512,
      temperature: 0.1,
    });
    const rawSummary =
      out.choices?.[0]?.message?.content || "Error summarizing entry.";

    // Remove any <think>...</think> block (including multi-line content)
    const cleanSummary = rawSummary
      .replace(/<think>[\s\S]*?<\/think>/gi, "")
      .trim();
    console.log(cleanSummary);
    return cleanSummary;
  } catch (error) {
    return handleError(error);
  }
};

// export const getUserQuestionsAction = async () => {
//   try {
//     const user = await getUser();
//     if (!user) throw new Error("You must be logged in to get AI responses");

//     return { errorMessage: null };
//   } catch (error) {
//     return handleError(error);
//   }
// };

export const followUpEntryAction = async (entry: String) => {
  try {
    const messages = [];

    const keys = Object.keys(entry);
    for (let i = 0; i < keys.length; i++) {
      const question = keys[i];
      const answer = entry[question];
      if (answer) {
        messages.push({ role: "user", content: question });
        messages.push({ role: "assistant", content: answer });
      }
    }

    const out = await HfInference.chatCompletion({
      model: "Qwen/Qwen3-32B",
      provider: "cerebras",
      messages: [
        {
          role: "system",
          content: `
            You are a helpful assistant that summarizes a user's journal entry. 
            Assume all responses to questions are related to the user's experiences. 
            Keep answers succinct and return a paragraph summary in second person, present tense looking to the future.

            Return all information in the format of valid JSON. All summaries should have a title a summarization, and 3 relevant tags. It should in the format below:
            
            {
              "title": "Enter a Passage Title Here",
              "summary": "Enter your Summary Here",
              "tags": ["tag1", "tag2", "tag3"],
              "sentiment": 0.0
            }
          `,
        },
        ...messages,
      ],
      max_tokens: 512,
      temperature: 0.1,
    });
    const rawSummary =
      out.choices?.[0]?.message?.content || "Error summarizing entry.";

    // Remove any <think>...</think> block (including multi-line content)
    const cleanSummary = rawSummary
      .replace(/<think>[\s\S]*?<\/think>/gi, "")
      .trim();
    console.log(cleanSummary);
    return cleanSummary;
  } catch (error) {
    return handleError(error);
  }
};
